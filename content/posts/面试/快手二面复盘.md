---
title: "快手二面复盘"
date: 2020-08-10T18:27:14+08:00
description: ""
draft: true
tags: []
categories: []
---

> 操作系统内核



> 自我介绍：自己的学习经历、特长、哪些方便比较感兴趣、哪些项目、哪些经验教训



> 类脑芯片、传统的cpu、传统的GPU和AI芯片

1. cpu采用传统的**冯诺依曼结构**，执行一条指令都需要从存储器中读取数据，根据指令对数据进行相应的操作。可以看出，CPU 的主要职责并不只是数据运算，还需要执行存储读取、指令分析、分支跳转等命令。深度学习算法通常需要进行海量的数据处理，用 CPU 执行算法时，CPU 将花费大量的时间在数据/指令的读取分析上，而 CPU的频率、**内存的带宽**等条件又不可能无限制提高，因此限制了处理器的性能。（总结：冯诺依曼结构，经常要去内存取数据 ）

2. GPU的控制相对cpu简单，大部分的晶体管可以组成各类**专用电路、多条流水线**，使得 GPU 的计算速度远高于 CPU；同时 GPU 拥有了更加强大的**浮点运算能力**，可以缓解深度学习算法的训练难题，释放人工智能的潜能。但 GPU 无法单独工作，必须由 CPU 进行控制调用才能工作，而且功耗比较高。（总结：1. gpu并行性高 2. 浮点计算能力强 3. 但是功耗太高）

3. 神经拟态芯片：神经拟态计算是模拟生物神经网络的计算机制。神经拟态计算从结构层面去逼近大脑，其研究工作还可进一步分为两个层次，一是神经网络层面，与之相应的是神经拟态架构和处理器，如 IBM 的TrueNorth 芯片，这种芯片把定制化的数字处理内核当作神经元，把内存作为突触。其逻辑结构与传统冯·诺依曼结构不同：它的**内存、CPU 和通信部件完全集成在一起**，因此信息的处理在本地进行，克服了传统计算机内存与 CPU 之间的速度瓶颈问题。同时神经元之间可以方便快捷地相互沟通，只要接收到其他神经元发过来的脉冲(动作电位)，这些神经元就会同时做动作。二是神经元与神经突触层面，与之相应的是元器件层面的创新（总结：1. 片上内存 2. 功耗低 3. 神经拟态）。

> 存算一体是怎么实现的

应该是片上内存，并没有实现存算一体；

> 忆阻器部件，既有存储和计算



> 类脑操作系统上我的工作量



> 车载为什么需要虚拟化



> kvm arm上的发展



> cpu的虚拟化怎么实现的？要解决哪些问题



> 宿主机能不能看到虚拟出来的vcpu



> 内存虚拟化怎么实现的

arm的话增加一层页表转换，也就是将gpa->hpa；

> 影子页表是什么



> 页表的转换输入和输出是什么



> io虚拟化



> 虚拟网卡执行流程



> shell 执行cat 文件命令，内核会做什么动作



> cfs的原理是什么



> 进程刚唤醒时的vruntime



> 抢占和休眠



> 虚拟地址转换成物理地址



> 加速页表查找

tlb

> 页表分级的好处



> 操作系统管理内存，伙伴系统有什么好处

1. 较好的解决外部碎片问题
2. 当需要分配若干个内存页面时，用于DMA的内存页面必须连续，伙伴算法很好的满足了这个要求

> 了解cgroup吗



